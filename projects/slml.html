<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Andrew Look">
<meta name="dcterms.date" content="2023-10-25">
<meta name="description" content="Overview of my project training ML models on a dataset of single-line drawings.">

<title>Single-Line Machine Learning – andrewlook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-listing/list.min.js"></script>
<script src="../site_libs/quarto-listing/quarto-listing.js"></script>
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-16fb397360ac6373c2344189e05b0de0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/videojs/video.min.js"></script>
<link href="../site_libs/quarto-contrib/videojs/video-js.css" rel="stylesheet">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-posts-list .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-title',{ data: ['index'] },{ data: ['categories'] },{ data: ['listing-date-sort'] },{ data: ['listing-title-sort'] }],
      
      searchColumns: ["listing-date","listing-title","listing-author"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-posts-list'] = new List('listing-posts-list', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  </script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="Single-Line Machine Learning – andrewlook">
<meta property="og:description" content="Overview of my project training ML models on a dataset of single-line drawings.">
<meta property="og:image" content="https://i.ibb.co/Vj5kRw3/download.png">
<meta property="og:site_name" content="andrewlook">
<meta name="twitter:title" content="Single-Line Machine Learning – andrewlook">
<meta name="twitter:description" content="Overview of my project training ML models on a dataset of single-line drawings.">
<meta name="twitter:image" content="https://i.ibb.co/Vj5kRw3/download.png">
<meta name="twitter:creator" content="@andrewlook">
<meta name="twitter:site" content="@andrewlook">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="https://i.ibb.co/GxrvZ2T/CROP-oneline-a-stoke1-5.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">andrew look</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../blog/index.html"> 
<span class="menu-text">blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../resume/index.html"> 
<span class="menu-text">resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about/index.html"> 
<span class="menu-text">about</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/andrewlook"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text">github</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://instagram.com/andrewlookart"> <i class="bi bi-instagram" role="img">
</i> 
<span class="menu-text">instagram</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://twitter.com/andrewlook"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text">twitter</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#single-line-machine-learning" id="toc-single-line-machine-learning" class="nav-link active" data-scroll-target="#single-line-machine-learning">Single-Line Machine Learning</a>
  <ul class="collapse">
  <li><a href="#why-this-project" id="toc-why-this-project" class="nav-link" data-scroll-target="#why-this-project">Why This Project</a></li>
  <li><a href="#preparing-the-dataset" id="toc-preparing-the-dataset" class="nav-link" data-scroll-target="#preparing-the-dataset">Preparing the Dataset</a></li>
  <li><a href="#sketchrnn-experiments" id="toc-sketchrnn-experiments" class="nav-link" data-scroll-target="#sketchrnn-experiments">SketchRNN Experiments</a></li>
  <li><a href="#interpreting-the-results" id="toc-interpreting-the-results" class="nav-link" data-scroll-target="#interpreting-the-results">Interpreting the Results</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/andrewlook/notebooks/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../projects/painting_deepdreams.html">projects</a></li><li class="breadcrumb-item"><a href="../projects/slml.html">Single-Line Machine Learning</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Single-Line Machine Learning</h1>
  <div class="quarto-categories">
    <div class="quarto-category">singleline</div>
    <div class="quarto-category">machinelearning</div>
    <div class="quarto-category">slml</div>
  </div>
  </div>

<div>
  <div class="description">
    Overview of my project training ML models on a dataset of single-line drawings.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Andrew Look </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 25, 2023</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">March 6, 2024</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="single-line-machine-learning" class="level1 page-columns page-full">
<h1>Single-Line Machine Learning</h1>
<p>Lately I’ve been working on training ML models to generate single-line drawings in my style. I’ve open-sourced the code for my <a href="https://github.com/andrewlook/singleline_models">models</a> and the code I used to prepare the <a href="https://github.com/andrewlook/singleline_dataset">dataset</a>.</p>
<p>I’ve started writing deep dives for each phase of the project.</p>
<div id="listing-posts-list" class="quarto-listing quarto-listing-container-table">
<table class="quarto-listing-table table">
<thead>
<tr>
<th>
Title
</th>
</tr>
</thead>
<tbody class="list">
<tr data-index="0" data-categories="c2luZ2xlbGluZSUyQ21hY2hpbmVsZWFybmluZyUyQ3NsbWw=" data-listing-date-sort="1697760000000" data-listing-file-modified-sort="1743626840223" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="3" data-listing-word-count-sort="516" data-listing-title-sort="SLML Part 0 - My Single-Line Drawing Practice" data-listing-filename-sort="slml_part0.qmd">
<td>
<a href="../blog/posts/slml_part0.html" class="title listing-title">SLML Part 0 - My Single-Line Drawing Practice</a>
</td>
</tr>
<tr data-index="1" data-categories="c2luZ2xlbGluZSUyQ21hY2hpbmVsZWFybmluZyUyQ3NsbWw=" data-listing-date-sort="1698364800000" data-listing-file-modified-sort="1743626840223" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="4" data-listing-word-count-sort="671" data-listing-title-sort="SLML Part 1 - Why I Decided to Train SketchRNN on My Drawings" data-listing-filename-sort="slml_part1.qmd">
<td>
<a href="../blog/posts/slml_part1.html" class="title listing-title">SLML Part 1 - Why I Decided to Train SketchRNN on My Drawings</a>
</td>
</tr>
<tr data-index="2" data-categories="c2luZ2xlbGluZSUyQ21hY2hpbmVsZWFybmluZyUyQ3NsbWw=" data-listing-date-sort="1698796800000" data-listing-file-modified-sort="1743626840223" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="6" data-listing-word-count-sort="1164" data-listing-title-sort="SLML Part 2 - Assembling the Dataset" data-listing-filename-sort="slml_part2.qmd">
<td>
<a href="../blog/posts/slml_part2.html" class="title listing-title">SLML Part 2 - Assembling the Dataset</a>
</td>
</tr>
<tr data-index="3" data-categories="c2luZ2xlbGluZSUyQ21hY2hpbmVsZWFybmluZyUyQ3NsbWw=" data-listing-date-sort="1699315200000" data-listing-file-modified-sort="1743626840223" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="2" data-listing-word-count-sort="365" data-listing-title-sort="SLML Part 3 - JPEG to SVG to Stroke-3" data-listing-filename-sort="slml_part3.qmd">
<td>
<a href="../blog/posts/slml_part3.html" class="title listing-title">SLML Part 3 - JPEG to SVG to Stroke-3</a>
</td>
</tr>
<tr data-index="4" data-categories="c2luZ2xlbGluZSUyQ21hY2hpbmVsZWFybmluZyUyQ3NsbWw=" data-listing-date-sort="1701561600000" data-listing-file-modified-sort="1743626840224" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="5" data-listing-word-count-sort="979" data-listing-title-sort="SLML Part 4 - SketchRNN Experiments: Minimum Stroke Length and RNN Regularization" data-listing-filename-sort="slml_part4.qmd">
<td>
<a href="../blog/posts/slml_part4.html" class="title listing-title">SLML Part 4 - SketchRNN Experiments: Minimum Stroke Length and RNN Regularization</a>
</td>
</tr>
<tr data-index="5" data-categories="c2luZ2xlbGluZSUyQ21hY2hpbmVsZWFybmluZyUyQ3NsbWw=" data-listing-date-sort="1702512000000" data-listing-file-modified-sort="1743626840224" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="9" data-listing-word-count-sort="1795" data-listing-title-sort="SLML Part 5 - SketchRNN Experiments: Path Preprocessing" data-listing-filename-sort="slml_part5.qmd">
<td>
<a href="../blog/posts/slml_part5.html" class="title listing-title">SLML Part 5 - SketchRNN Experiments: Path Preprocessing</a>
</td>
</tr>
<tr data-index="6" data-categories="c2luZ2xlbGluZSUyQ21hY2hpbmVsZWFybmluZyUyQ3NsbWw=" data-listing-date-sort="1704326400000" data-listing-file-modified-sort="1743626840224" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="6" data-listing-word-count-sort="1047" data-listing-title-sort="SLML Part 6 - SketchRNN Experiments: Granular Visual Filtering" data-listing-filename-sort="slml_part6.qmd">
<td>
<a href="../blog/posts/slml_part6.html" class="title listing-title">SLML Part 6 - SketchRNN Experiments: Granular Visual Filtering</a>
</td>
</tr>
<tr data-index="7" data-categories="c2luZ2xlbGluZSUyQ21hY2hpbmVsZWFybmluZyUyQ3NsbWw=" data-listing-date-sort="1704326400000" data-listing-file-modified-sort="1743626840224" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="3" data-listing-word-count-sort="523" data-listing-title-sort="SLML Part 7 - SketchRNN Experiments: Data Augmentation" data-listing-filename-sort="slml_part7.qmd">
<td>
<a href="../blog/posts/slml_part7.html" class="title listing-title">SLML Part 7 - SketchRNN Experiments: Data Augmentation</a>
</td>
</tr>
</tbody>
</table>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>
<p>This page includes a broader overview of the story as a whole, linking to the individual sections for more detail.</p>
<section id="why-this-project" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="why-this-project">Why This Project</h2>
<p>In <a href="../blog/posts/slml_part0.html">part 0</a> I share how I got started making single-line drawings, and why I found them interesting enough to make them as a daily practice.</p>
<div class="column-body-outset">
<div class="quarto-video"><video id="video_shortcode_videojs_video1" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="https://storage.googleapis.com/andrewlook-art-assets/andrewlook.com/videos/sb20p077-drawing-vid.mp4"></video></div>
</div>
<p>In <a href="../blog/posts/slml_part1.html">part 1 - Discovering SketchRNN</a> I cover how SketchRNN captured my imagination and why I decided to try training it on my own data. For example, I imagined turning the “variability” up, and generating new drawings based on my old ones?</p>
<div class="page-columns page-full">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><a href="https://i.ibb.co/h7nQM0n/distill-variation.gif" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-1" title="distill.pub’s handwriting demo"><img src="https://i.ibb.co/h7nQM0n/distill-variation.gif" class="img-fluid figure-img column-body-outset" alt="distill.pub’s handwriting demo"></a></p>
<figcaption>distill.pub’s <a href="https://distill.pub/2016/handwriting/">handwriting demo</a></figcaption>
</figure>
</div>
</div>
<p>I hit my first roadbloack when I reached out to the authors of SketchRNN. They estimated that I’d need thousands of examples in order to train a model, but I only had a few hundred at the time.</p>
<p>I decided to keep making drawings in my sketchbooks, numbering the pages, and scanning them to store with a standardized file naming scheme.</p>
<div class="column-body-outset">
<div class="quarto-video"><video id="video_shortcode_videojs_video2" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="https://storage.googleapis.com/andrewlook-art-assets/andrewlook.com/videos/hustl-20231207023837-sb77-scanning.mp4"></video></div>
</div>
<p>In the back of my mind, I held on to the idea that one day I’d have enough drawings to train a model on them.</p>
<p>Several years went by. More sketchbooks accumulated. Eventually, I ran a file count and saw a few thousand distinct drawings.</p>
<div id="fig-lines" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lines-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: center;">
<p><a href="https://i.ibb.co/TrdbwR2/sb48p072.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;1: Some example single-line drawings from my sketchbooks."><img src="https://i.ibb.co/TrdbwR2/sb48p072.jpg" class="img-fluid figure-img"></a></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: center;">
<p><a href="https://i.ibb.co/xfqZZF0/sb67p077.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;1: Some example single-line drawings from my sketchbooks."><img src="https://i.ibb.co/xfqZZF0/sb67p077.jpg" class="img-fluid figure-img"></a></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: center;">
<p><a href="https://i.ibb.co/5MtbpVL/sb67p004.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;1: Some example single-line drawings from my sketchbooks."><img src="https://i.ibb.co/5MtbpVL/sb67p004.jpg" class="img-fluid figure-img"></a></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: center;">
<p><a href="https://i.ibb.co/RvJ6DpK/sb38p073-gown2.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;1: Some example single-line drawings from my sketchbooks."><img src="https://i.ibb.co/RvJ6DpK/sb38p073-gown2.jpg" class="img-fluid figure-img"></a></p>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lines-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Some example single-line drawings from my sketchbooks.
</figcaption>
</figure>
</div>
</section>
<section id="preparing-the-dataset" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="preparing-the-dataset">Preparing the Dataset</h2>
<p>I was finally ready to get started. I was going to need:</p>
<ol type="1">
<li>a thousand JPEGs of my drawings (at least)</li>
<li>a stroke-3 conversion process for my JPEG scans</li>
<li>a SketchRNN model and trainer</li>
<li>the patience to experiment with hyperparameters</li>
</ol>
<p>I started by collecting my sketchbook page JPEGs into usable training data.</p>
<div id="fig-watercolors" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-watercolors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://i.ibb.co/KFPv1dp/sb26p068-purple-hair.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="sb26p068-purple-hair"><img src="https://i.ibb.co/KFPv1dp/sb26p068-purple-hair.jpg" class="img-fluid figure-img"></a></p>
<figcaption>sb26p068-purple-hair</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://i.ibb.co/HqsynCv/sb55p069-color.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="sb55p069-color"><img src="https://i.ibb.co/HqsynCv/sb55p069-color.jpg" class="img-fluid figure-img"></a></p>
<figcaption>sb55p069-color</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://i.ibb.co/jW8rBNX/sb26p098-pickle-toast.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="sb26p098-pickle-toast"><img src="https://i.ibb.co/jW8rBNX/sb26p098-pickle-toast.jpg" class="img-fluid figure-img"></a></p>
<figcaption>sb26p098-pickle-toast</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://i.ibb.co/ScRSctH/sb26p069-red-nose.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="sb26p069-red-nose"><img src="https://i.ibb.co/ScRSctH/sb26p069-red-nose.jpg" class="img-fluid figure-img"></a></p>
<figcaption>sb26p069-red-nose</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-watercolors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Some watercolor examples from my sketchbooks.
</figcaption>
</figure>
</div>
<p>In <a href="../blog/posts/slml_part2.html">part 2 - Embedding Filtering</a>, I cover how I’m using embeddings to filter my dataset of drawings. I used embeddings to solve the problem of filtering everything out of my sketchbook data that wasn’t a single-line drawing - particularly my watercolors.</p>
<p>I also made an exploratory browser to visualize the embedding space of the drawings, and published it at <a href="https://projector.andrewlook.com">projector.andrewlook.com</a>. Here’s a demo video:</p>
<div class="column-body-outset">
<div class="quarto-video"><video id="video_shortcode_videojs_video3" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="https://storage.googleapis.com/andrewlook-art-assets/andrewlook.com/videos/emb-projector.mp4"></video></div>
</div>
<p>In <a href="../blog/posts/slml_part3.html">part 3 - Dataset Vectorization</a>, I cover how I’m vectorizing the scans to prepare them for RNN/transformer training. At this stage in the process, my drawings were converted to centerline-traced vector paths, but they were represented as a series of separate strokes. It’s visible in <a href="#fig-sepstrokes" class="quarto-xref">Figure&nbsp;3</a> how the strokes are out of order, since strokes don’t start where the previous stroke left off.</p>
<div id="fig-sepstrokes" class="column-body quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sepstrokes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video"><video id="video_shortcode_videojs_video4" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="https://storage.googleapis.com/andrewlook-art-assets/andrewlook.com/videos/stroke3-sepstrokes1.mp4"></video></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sepstrokes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Example of separate strokes after my vectorization process.
</figcaption>
</figure>
</div>
<!-- ![separate strokes](https://i.ibb.co/s21gLTQ/stroke3-01-sepstrokes.png) -->
</section>
<section id="sketchrnn-experiments" class="level2">
<h2 class="anchored" data-anchor-id="sketchrnn-experiments">SketchRNN Experiments</h2>
<!-- TODO(important): call out parts 5 and 6 -->
<p><a href="../blog/posts/slml_part4.html">Part 4</a> covers how the dataset I used to train my first model contained drawings with too many short strokes, as in <a href="#fig-sepstrokes" class="quarto-xref">Figure&nbsp;3</a>. Models trained on this dataset produced frenetic drawings such as <a href="#fig-before-sse" class="quarto-xref">Figure&nbsp;4 (a)</a>. I experimented with some RNN training improvements and after filtering short strokes out of my first datasets and training a new model I saw a big improvment, as in <a href="#fig-after-sse" class="quarto-xref">Figure&nbsp;4 (b)</a>.</p>
<div id="fig-i16-results" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-i16-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-i16-results" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-before-sse" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-before-sse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/Nnrn9jL/phase1-sample-0111-epoch-00330-decoded.png" class="lightbox" data-gallery="fig-i16-results" title="Figure&nbsp;4&nbsp;(a): Before Short-Stroke Exclusion"><img src="https://i.ibb.co/Nnrn9jL/phase1-sample-0111-epoch-00330-decoded.png" class="img-fluid figure-img" data-ref-parent="fig-i16-results"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-before-sse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Before Short-Stroke Exclusion
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-i16-results" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-after-sse" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-after-sse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/jzgHHPS/phase2-sample-0145-epoch-11500-decoded.png" class="lightbox" data-gallery="fig-i16-results" title="Figure&nbsp;4&nbsp;(b): After Short-Stroke Exclusion"><img src="https://i.ibb.co/jzgHHPS/phase2-sample-0145-epoch-11500-decoded.png" class="img-fluid figure-img" data-ref-parent="fig-i16-results"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-after-sse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) After Short-Stroke Exclusion
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-i16-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Sample generated results from models trained before and after filtering out strokes with less than 10 points.
</figcaption>
</figure>
</div>
<!--
:::{#fig-i16-results .column-screen-inset layout-ncol=3}
![](https://i.ibb.co/Nnrn9jL/phase1-sample-0111-epoch-00330-decoded.png)

![](https://i.ibb.co/fSnW50p/phase1-sample-0115-epoch-00310-decoded.png)

![](https://i.ibb.co/LNdGhBb/phase1-sample-0177-epoch-06000-decoded.png)

Generated outputs from SketchRNN trained on dataset `look_i16`.
:::
:::{#fig-i16-results .column-screen-inset layout-ncol=3}
![](https://i.ibb.co/hXBK8Zb/phase2-sample-0066-epoch-11700-decoded.png)

![](https://i.ibb.co/jzgHHPS/phase2-sample-0145-epoch-11500-decoded.png)

![](https://i.ibb.co/0mwbJBw/phase2-sample-0291-epoch-13200-decoded.png)

Generated outputs from SketchRNN trained on dataset `look_i16__minn10`.
:::
-->
<p><a href="../blog/posts/slml_part5.html">Part 5</a> covers improvements I made to my preprocessing of the dataset by <a href="https://singleline-dataset.andrewlook.com/strokes.html">joining SVG paths</a> up into continuous lines so that the model could learn from longer sequences.</p>
<div id="fig-joining" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-joining-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-joining" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-original" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-original-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/s21gLTQ/stroke3-01-sepstrokes.png" class="lightbox" data-gallery="fig-joining" title="Figure&nbsp;5&nbsp;(a): Original: 22 strokes"><img src="https://i.ibb.co/s21gLTQ/stroke3-01-sepstrokes.png" class="img-fluid figure-img" data-ref-parent="fig-joining"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-original-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Original: 22 strokes
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-joining" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-joined" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-joined-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/602dKpr/stroke3-01-joinedstrokes.png" class="lightbox" data-gallery="fig-joining" title="Figure&nbsp;5&nbsp;(b): After path-joining: 4 strokes"><img src="https://i.ibb.co/602dKpr/stroke3-01-joinedstrokes.png" class="img-fluid figure-img" data-ref-parent="fig-joining"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-joined-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) After path-joining: 4 strokes
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-joining" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-spliced" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-spliced-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/rtnZMq1/stroke3-01-splicedstrokes1.png" class="lightbox" data-gallery="fig-joining" title="Figure&nbsp;5&nbsp;(c): After path-splicing: 2 strokes"><img src="https://i.ibb.co/rtnZMq1/stroke3-01-splicedstrokes1.png" class="img-fluid figure-img" data-ref-parent="fig-joining"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-spliced-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) After path-splicing: 2 strokes
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-joining-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Comparison of number of strokes before and after preprocessing, with one color per stroke.
</figcaption>
</figure>
</div>
<!--
Here's a debug video I made to flip through part of my dataset and watch drawings go from multiple strokes (one color per stroke) to a single stroke:

:::{.column-body}












:::
-->
<p>The generated results at this stage were uncanny, but showed a big improvement from the initial results. There were at least some recognizable faces and bodies, as seen in <a href="#fig-gen-spliced" class="quarto-xref">Figure&nbsp;6</a>.</p>
<div id="fig-gen-spliced" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gen-spliced-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><a href="https://i.ibb.co/ZGLMZ4H/phase3-runid-dhzx8671-epoch-00200-sample-0338-decoded.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Figure&nbsp;6: Generated samples from a model trained on path-spliced dataset."><img src="https://i.ibb.co/ZGLMZ4H/phase3-runid-dhzx8671-epoch-00200-sample-0338-decoded.png" class="img-fluid figure-img"></a></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><a href="https://i.ibb.co/5TVZG6H/phase3-runid-dhzx8671-epoch-00400-sample-0338-decoded.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" title="Figure&nbsp;6: Generated samples from a model trained on path-spliced dataset."><img src="https://i.ibb.co/5TVZG6H/phase3-runid-dhzx8671-epoch-00400-sample-0338-decoded.png" class="img-fluid figure-img"></a></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><a href="https://i.ibb.co/KxRj62q/phase3-runid-093xwcex-epoch-01000-sample-0061-decoded.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Figure&nbsp;6: Generated samples from a model trained on path-spliced dataset."><img src="https://i.ibb.co/KxRj62q/phase3-runid-093xwcex-epoch-01000-sample-0061-decoded.png" class="img-fluid figure-img"></a></p>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gen-spliced-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Generated samples from a model trained on path-spliced dataset.
</figcaption>
</figure>
</div>
<p>Also in Part 5, I a preprocessing step to decompose strokes into seperate drawings if their bounding boxes didn’t overlap sufficiently. The size of the dataset roughly doubled, since sketchbook pages containing multiple drawings were broken out into separate training examples as in <a href="#fig-bbox-split-example" class="quarto-xref">Figure&nbsp;7</a>.</p>
<div id="fig-bbox-split-example" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bbox-split-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-bbox-split-example" style="flex-basis: 25.0%;justify-content: flex-start;">
<div id="fig-prebbox" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-prebbox-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/SrpsMWZ/bbox-20.png" class="lightbox" data-gallery="fig-bbox-split-example" title="Figure&nbsp;7&nbsp;(a): Original"><img src="https://i.ibb.co/SrpsMWZ/bbox-20.png" class="img-fluid figure-img" data-ref-parent="fig-bbox-split-example"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-prebbox-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Original
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-bbox-split-example" style="flex-basis: 25.0%;justify-content: flex-start;">
<div id="fig-postbbox-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-postbbox-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/PNLqQLG/bbox-21.png" class="lightbox" data-gallery="fig-bbox-split-example" title="Figure&nbsp;7&nbsp;(b): "><img src="https://i.ibb.co/PNLqQLG/bbox-21.png" id="fig-postbbox-1" class="img-fluid figure-img" data-ref-parent="fig-bbox-split-example"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-postbbox-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b)
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-bbox-split-example" style="flex-basis: 25.0%;justify-content: flex-start;">
<div id="fig-postbbox-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-postbbox-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/wWKK6zC/bbox-22.png" class="lightbox" data-gallery="fig-bbox-split-example" title="Figure&nbsp;7&nbsp;(c): "><img src="https://i.ibb.co/wWKK6zC/bbox-22.png" id="fig-postbbox-2" class="img-fluid figure-img" data-ref-parent="fig-bbox-split-example"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-postbbox-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c)
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-bbox-split-example" style="flex-basis: 25.0%;justify-content: flex-start;">
<div id="fig-postbbox-3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-postbbox-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/N18YMC0/bbox-23.png" class="lightbox" data-gallery="fig-bbox-split-example" title="Figure&nbsp;7&nbsp;(d): "><img src="https://i.ibb.co/N18YMC0/bbox-23.png" id="fig-postbbox-3" class="img-fluid figure-img" data-ref-parent="fig-bbox-split-example"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-postbbox-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d)
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bbox-split-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Original drawing (left) was one row in dataset <code>v2-splicedata</code>. The rightmost three drawings are distinct rows in dataset <code>20231214</code>.
</figcaption>
</figure>
</div>
<p><a href="../blog/posts/slml_part6.html">Part 6</a> covers how I filtered drawings by visual similarity. Though I did an earlier pass on visual similarity to filter watercolors out from my single-line drawings, this time I wanted to explore the embedding space of the individual drawings after bounding-box separation had been applied. I found that clustering the drawing embeddings identified clusters I wanted to exlcude from the training data like <a href="#fig-c0" class="quarto-xref">Figure&nbsp;8 (a)</a> and <a href="#fig-c13" class="quarto-xref">Figure&nbsp;8 (b)</a>, and helped me identify clusters that I wanted to include in the training data like <a href="#fig-c5" class="quarto-xref">Figure&nbsp;8 (c)</a>.</p>
<div id="fig-chains" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-chains-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-chains" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-c0" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-c0-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/ZghFLD3/c0.png" class="lightbox" data-gallery="fig-chains" title="Figure&nbsp;8&nbsp;(a): Cluster of complex drawings I wanted to filter out"><img src="https://i.ibb.co/ZghFLD3/c0.png" class="img-fluid figure-img" data-ref-parent="fig-chains"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-c0-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Cluster of complex drawings I wanted to filter out
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-chains" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-c13" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-c13-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/mBnwc2N/c13.png" class="lightbox" data-gallery="fig-chains" title="Figure&nbsp;8&nbsp;(b): Cluster of simple drawings I wanted to filter out"><img src="https://i.ibb.co/mBnwc2N/c13.png" class="img-fluid figure-img" data-ref-parent="fig-chains"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-c13-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Cluster of simple drawings I wanted to filter out
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-chains" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-c5" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-c5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://i.ibb.co/3MsTpmc/c5.png" class="lightbox" data-gallery="fig-chains" title="Figure&nbsp;8&nbsp;(c): Cluster of good drawings I wanted to include"><img src="https://i.ibb.co/3MsTpmc/c5.png" class="img-fluid figure-img" data-ref-parent="fig-chains"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-c5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Cluster of good drawings I wanted to include
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-chains-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Example groupings after running K-Means on visual embeddings of individual drawings.
</figcaption>
</figure>
</div>
<p>The drawings generated by models trained on this visually-filtered dataset started to look recognizable as containing distinct people or faces, as in <a href="#fig-gen-bboxsep" class="quarto-xref">Figure&nbsp;9</a>. Still odd and convoluted, but interesting enough to give me new ideas for drawings or paintings.</p>
<div id="fig-gen-bboxsep" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gen-bboxsep-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><a href="https://i.ibb.co/85p1XNk/phase5-test.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25" title="Figure&nbsp;9: Generated samples after training with visual filtering on bbox-separated dataset."><img src="https://i.ibb.co/85p1XNk/phase5-test.png" class="img-fluid figure-img"></a></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><a href="https://i.ibb.co/R41PJTS/phase5-test2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26" title="Figure&nbsp;9: Generated samples after training with visual filtering on bbox-separated dataset."><img src="https://i.ibb.co/R41PJTS/phase5-test2.png" class="img-fluid figure-img"></a></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><a href="https://i.ibb.co/SymDvdW/phase5-test3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27" title="Figure&nbsp;9: Generated samples after training with visual filtering on bbox-separated dataset."><img src="https://i.ibb.co/SymDvdW/phase5-test3.png" class="img-fluid figure-img"></a></p>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gen-bboxsep-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Generated samples after training with visual filtering on bbox-separated dataset.
</figcaption>
</figure>
</div>
<p><a href="../blog/posts/slml_part7.html">Part 7</a> covers experiments I tried using data augmentation, using tricks to take my existing set of drawings and create a more diverse set of training data. For regular computer vision algorithms looking at images in terms of pixels, it’s common to randomly crop the images, flip them horizontally, and change the colors. For vector drawings like I’m working with, there are a different set of techniques available.</p>
<div id="fig-data-aug" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-data-aug-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://i.ibb.co/sq9YtDX/aug0.png" class="lightbox" data-gallery="quarto-lightbox-gallery-28" title="Original drawing"><img src="https://i.ibb.co/sq9YtDX/aug0.png" class="img-fluid figure-img"></a></p>
<figcaption>Original drawing</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://i.ibb.co/VDp5d3D/aug1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29" title="After “Stroke Augmentation” drops points from lines at random"><img src="https://i.ibb.co/VDp5d3D/aug1.png" class="img-fluid figure-img"></a></p>
<figcaption>After “Stroke Augmentation” drops points from lines at random</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://i.ibb.co/z59gv5S/aug2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-30" title="Randomly rotated and scaled"><img src="https://i.ibb.co/z59gv5S/aug2.png" class="img-fluid figure-img"></a></p>
<figcaption>Randomly rotated and scaled</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-data-aug-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Examples of data augmentation.
</figcaption>
</figure>
</div>
</section>
<section id="interpreting-the-results" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="interpreting-the-results">Interpreting the Results</h2>
<!-- TODO(important): split into a separate analysis section? -->
<p>It has also been fun to connect the model’s generation function to an animation builder, so I can watch the machine “draw” in real time. Compared with viewing a static output, the animations reminds me that part of what I love about single-line drawings is the surprise as a viewer.</p>
<div class="quarto-video"><video id="video_shortcode_videojs_video6" height="400" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="https://storage.googleapis.com/andrewlook-art-assets/andrewlook.com/videos/video-8.mp4"></video></div>
<p>The drawing might start off nonsensical, and then end up with something recognizable enough to be an abstract figure drawing. Even when I’m drawing, I don’t always know where the drawing is going to end up.</p>
<div class="quarto-video"><video id="video_shortcode_videojs_video7" height="400" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title=""><source src="https://storage.googleapis.com/andrewlook-art-assets/andrewlook.com/videos/video-11.mp4"></video></div>
<p>I’m adjusting as my hand moves, and adapting to any unexpected moves or mistakes to try and arrive at a drawing that I like. This is not so different from how SketchRNN generates drawings. One way to look at it is that I’m sampling from a probability distribution of possible next moves, and my decision is made by the muscle memory of what’s happened so far.</p>
<p>Looking at some of the results generated from my SketchRNN models such as <a href="#fig-gen-bboxsep" class="quarto-xref">Figure&nbsp;9</a>, they remind me of an experiment I’ve tried in drawing with my eyes closed.</p>
<p>I was curious about how much I’m adjusting drawings based on what I see while I’m drawing. I wanted to see how much of my drawings come exclusively from the muscle memory I’ve developed in drawing faces.</p>
<p>Drawing with eyes closed is a great analogy for how SketchRNN draws. The model is only receiving information about the path has traveled so far. No visual information is available about what the final drawing looks like in pixel space as a real image.</p>
<div>

</div>
<div class="column-screen-inset quarto-layout-panel" data-layout-ncol="3">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><a href="https://i.ibb.co/xGVJtrL/067.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-31"><img src="https://i.ibb.co/xGVJtrL/067.jpg" class="img-fluid"></a></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><a href="https://i.ibb.co/2jMwq12/sb66p089-eyesclosed.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-32"><img src="https://i.ibb.co/2jMwq12/sb66p089-eyesclosed.jpg" class="img-fluid"></a></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<p><img src="https://i.ibb.co/vcwnvTX/sb66p091-eyesclosed.jpg" class="img-fluid"> <!-- 
![](https://i.ibb.co/f2YJ55v/065.jpg)

![](https://i.ibb.co/LPHSH29/066.jpg)
--></p>
</div>
</div>
</div>
<p>Errors like the ones in my eyes-closed drawings made me think about a common issue with models like SketchRNN that rely on recurrent neural networks.</p>
<p>The problem of <a href="https://ai-master.gitbooks.io/recurrent-neural-network/content/the-problem-of-long-term-dependencies.html">“long-term dependencies”</a> refers to the poor performance RNN’s exhibit in understand things that are too far apart in a sequence.</p>
<p>In the case of a drawing, long term dependencies would be things that are far apart in terms of the path the pen takes.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://ai-master.gitbooks.io/recurrent-neural-network/content/assets/RNN_connection.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-33" title="Recurrent neural networks read a sequence and update the “hidden” layer. The hidden layers act as a kind of memory, allowing later steps in the sequence to incorporate information from earlier parts of the sequence. Each step incorporates more information to the same vector before passing it to the next step in the sequnce. As the RNN model steps through the sequence, the signal from earlier in the sequence tends to “decay” in favor of more recent information later in the sequence."><img src="https://ai-master.gitbooks.io/recurrent-neural-network/content/assets/RNN_connection.jpg" class="img-fluid figure-img" alt="Recurrent neural networks read a sequence and update the “hidden” layer. The hidden layers act as a kind of memory, allowing later steps in the sequence to incorporate information from earlier parts of the sequence. Each step incorporates more information to the same vector before passing it to the next step in the sequnce. As the RNN model steps through the sequence, the signal from earlier in the sequence tends to “decay” in favor of more recent information later in the sequence."></a></p>
<figcaption>Recurrent neural networks read a sequence and update the “hidden” layer. The hidden layers act as a kind of memory, allowing later steps in the sequence to incorporate information from earlier parts of the sequence. Each step incorporates more information to the same vector before passing it to the next step in the sequnce. As the RNN model steps through the sequence, the signal from earlier in the sequence tends to “decay” in favor of more recent information later in the sequence.</figcaption>
</figure>
</div>
<p>The long-term dependency problem makes intuitive sense to me when I consider my eyes-closed drawings.</p>
<p>Apparently I have muscle memory when I draw eyes and a note in close proximity, and in drawings lips and a chin, but without looking it’s hard to swoop down from eyes to lips and have them be aligned to the nose I drew earlier.</p>
<p><a href="https://i.ibb.co/4ZB8g6x/eyesclosed-explainer.png" class="lightbox" data-gallery="quarto-lightbox-gallery-34"><img src="https://i.ibb.co/4ZB8g6x/eyesclosed-explainer.png" class="img-fluid"></a></p>
<!--
| ![phase5-test](https://i.ibb.co/85p1XNk/phase5-test.png) | ![phase5-test2](https://i.ibb.co/R41PJTS/phase5-test2.png) |
| ---- | ---- |
| ![phase5-test3](https://i.ibb.co/SymDvdW/phase5-test3.png) | ![phase5-test4](https://i.ibb.co/xqfCt4n/phase5-test4.png) |
| ![phase5-test5](https://i.ibb.co/cbh6D3F/phase5-test5.png) |  |















-->
<p>This got me interested in how <a href="https://jalammar.github.io/illustrated-transformer/">Transformer models</a> use attention mechanisms to let each step in the sequence take into account the entire sequence at once.</p>
<p><a href="https://jalammar.github.io/images/t/transformer_self-attention_visualization.png" class="lightbox" data-gallery="quarto-lightbox-gallery-35"><img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization.png" class="img-fluid"></a></p>
<p>I came across a paper called <a href="https://arxiv.org/abs/2002.10381">Sketchformer: Transformer-based Representation for Sketched Structure</a>, which made a transformer model based on SketchRNN. I decided to try adapting that model for my dataset, and seeing how it compares on handling long-term dependencies.</p>
<div class="page-columns page-full" data-cap-location="bottom">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><a href="https://i.ibb.co/rx1nbmt/sketchformer-architecture.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-36" title="Architecture of the SketchFormer model."><img src="https://i.ibb.co/rx1nbmt/sketchformer-architecture.png" class="img-fluid figure-img column-body-outset" alt="Architecture of the SketchFormer model."></a></p>
<figcaption>Architecture of the SketchFormer model.</figcaption>
</figure>
</div>
</div>
<p>In my next section on “Training Sketchformer” <em>(coming soon)</em>, I cover my experiments using a transformer model instead of an RNN, to see if the model can better handle long-term dependencies within the drawings.</p>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/andrewlook\.com\/notebooks");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="andrewlook/notebooks" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/andrewlook/notebooks/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer><script>videojs(video_shortcode_videojs_video1);</script>
<script>videojs(video_shortcode_videojs_video2);</script>
<script>videojs(video_shortcode_videojs_video3);</script>
<script>videojs(video_shortcode_videojs_video4);</script>
<script>videojs(video_shortcode_videojs_video5);</script>
<script>videojs(video_shortcode_videojs_video6);</script>
<script>videojs(video_shortcode_videojs_video7);</script>
<script>videojs(video_shortcode_videojs_video8);</script>
<script>videojs(video_shortcode_videojs_video9);</script>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>